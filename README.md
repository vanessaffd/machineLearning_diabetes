# Machine Learning - Diabetes
Script em python que avalia cinco modelos de análise preditiva sobre fatores de risco de Diabetes


No presente projeto cinco modelos preditivos de machine Learn foram treinados, de forma supervisionada, para prever a ocorrência de Diabetes entre o público analisado. O objetivo foi avaliar a capacidade de predizer a incidência da doença com base em fatores de risco conhecidos. Utilizamos um dataset hospedado na plataforma Kaggle com um tamanho original de 100.000 registros e 9 atributos, incluindo o status de incidência de diabetes. Utilizamos o Jupyter Notebook e a linguagem Python no projeto, em virtude da ampla disponibilidade de recursos e bibliotecas voltadas para a análise de dados e machine learn.

Partindo de um dataframe com dados médicos e demográficos, acompanhados do seu status para a incidência de diabetes, primeiramente removemos 35.816 registros cujo dataset  não apresentava a informação para o histórico de tabagismo da amostra. O próximo passo foi utilizar o método get_dummies, da biblioteca Pandas, para transformar as variáveis categóricas em variáveis numéricas binárias, tendo em vista que os algoritmos de aprendizado de máquina possuem um desempenho melhor quando analisam esse tipo de dado. A metodologia foi aplicada nas colunas ‘gender’ e  'smoking_history'.

O próximo passo foi aplicarmos a metodologia  MinMaxScaler, da biblioteca scikit-learn, para normalizamos os dados das colunas 'bmi', 'HbA1c_level' e 'blood_glucose_level'. Na sequência dividimos o dataset tratado em variáveis independentes (features), aquelas variáveis que os modelos usarão para fazer as predições, e a variável dependente (ou target), a variável que queremos prever. Cada um desses datasets resultantes, usualmente chamados respectivamente de X (features) e y (target), foram então divididos em X-Treino, X_teste, y_treino e y_teste. Dessa forma temos uma amostra para treinar os modelos e outra para avaliar a eficiência dos modelos já treinados.

Foram avaliados um total de cinco modelos preditivos: Regressão Logística, Árvore de Decisão, SVC (Support Vector Classifier), Random Forest e o modelo K-Nearest Neighbors. Embora alguns modelos também possam ser usados para regressão, a classificação é a aplicação mais típica para todos os modelos utilizados. Utilizando a linguagem Python e suas bibliotecas de análise de dados,os modelos foram então avaliados quanto ao valor de F1-Score. Essa métrica de desempenho é usada em aprendizado de máquina e estatística para avaliar a eficácia de modelos de classificação. Ela é especialmente útil quando há desbalanceamento de classes, ou seja, quando uma classe é muito mais comum do que outra no conjunto de dados, como é o caso de incidência de doenças em uma amostra. Identificamos que o modelo Randon Forest obteve o melhor desempenho, apresentando um valor de F1-Score igual a 0,800, seguido pelo modelo de Árvore de Decisão, com 0,738 de F1-Score.

O resultado demonstra boa capacidade preditiva com base nos dados de fatores de risco, tais como obesidade, histórico de tabagismo e hipertensão. Nesse sentido, o modelo poderá ter diversas aplicações práticas tais como apoio à tomada de decisão em saúde pública, triagem médica, medicina preventiva e pesquisas epidemiológicas que levem em consideração esses atributos demográficos, especialmente em cenários de desbalanceamento de classes, como a baixa incidência de doenças em mesmo grandes populações.
